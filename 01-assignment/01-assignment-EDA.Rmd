---
title: "Assignment 01: Exploratory Data Analysis"
author: "Flemming Wu"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---
#### We will work with air pollution data from the U.S. Environmental Protection Agency (EPA). The primary question you will answer is whether daily concentrations of PM 2.5 (particulate matter air pollution with aerodynamic diameter less than 2.5 m) have decreased in California over the last 15 years (from 2004 to 2019).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/PM566/GitHub/01-assignment")
```

```{r, message = FALSE}
library(tidyverse)
library(leaflet)
library(webshot)
```


##### 1. Read in the data using data.table(). For each of the two datasets, check the dimensions, headers, footers, variable names, and variable types. Check for any data issues, particularly in the key variable you are analyzing. Make sure you write up a summary of all of your findings.

```{r Downloading and reading in csv files, message=FALSE}
if(!file.exists("data_2004.csv")){
  download.file("https://raw.githubusercontent.com/flemm0/PM_566/main/01-assignment/data_2004.csv", destfile = "data_2004.csv", method="libcurl", timeout = 60)
}

if(!file.exists("data_2019.csv")){
  download.file("https://raw.githubusercontent.com/flemm0/PM_566/main/01-assignment/data_2019.csv", destfile = "data_2019.csv", method="libcurl", timeout=60)
}

data_2004 <- data.table::fread("data_2004.csv")
data_2019 <- data.table::fread("data_2019.csv")
```

```{r check dimensions}
noquote(c("2004 dimensions: ", dim(data_2004)))
noquote(c("2019 dimensions: ", dim(data_2019)))
```
```{r Check how many more observations there are for 2019}
dim(data_2019)[1]/dim(data_2004)[1]
```
There are almost 3 times as many observations for PM 2.5 concentration in 2019 compared to 2004.

```{r check head and tail for 2004}
head(data_2004)
tail(data_2004)
```

```{r check head and tail for 2019}
head(data_2019)
tail(data_2019)
```

```{r Check variables for 2004 data}
str(data_2004)
```

```{r Check variables for 2019 data}
str(data_2019)
```
It looks like some of the column names are separated by space, so will update them to be syntactically valid.
```{r Update column names}
names(data_2004) <- make.names(names(data_2004))
names(data_2019) <- make.names(names(data_2019))
```

Checking Key Variable: PM 2.5 Concentration
```{r Check PM 2.5 concentration values for 2004}
summary(data_2004$Daily.Mean.PM2.5.Concentration)
```
Looks like some observations are below 0.

```{r Check how many PM 2.5 concentration observations are below 0}
table(data_2004$Daily.Mean.PM2.5.Concentration) %>% head()
```
One observation for PM 2.5 concentration is negative.

```{r Check the maximum values}
quantile(data_2004$Daily.Mean.PM2.5.Concentration, seq(0, 1, 0.1))
```
Looks like 10% of the data lie between concentration levels of 27 and 251.


```{r Check PM 2.5 concentration values for 2019}
summary(data_2019$Daily.Mean.PM2.5.Concentration)
```
```{r}
table(data_2019$Daily.Mean.PM2.5.Concentration) %>% head()
```
Looks like 2019 has many more 2.5 concentration observations that are below 0.

```{r}
quantile(data_2019$Daily.Mean.PM2.5.Concentration, seq(0, 1, 0.1))
```
10% of the data lie between concentration levels of 14.2 and 120.9. Additionally, the maximum 2.5 concentration observation is less than half that of the 2004 data. This is plausible due to increase of effort to reduce air pollution levels.

The EPA standard for PM 2.5 concentration post-1997 is 65 ug/m3 and was lowered to 35 ug/m3 since 2006.

The negative PM 2.5 concentration levels pose a problem for answering the question and will be removed.







##### 2. Combine the two years of data into one data frame. Use the Date variable to create a new column for year, which will serve as an identifier. Change the names of the key variables so that they are easier to refer to in your code.

```{r Changing dates to datetime type and creating year column}
data_2004 <- mutate(data_2004, Date = as.Date(Date, "%m/%d/%Y"))
data_2004$year <- format(as.Date(data_2004$Date, format="%m/%d/%Y"),"%Y")


data_2019 <- mutate(data_2019, Date = as.Date(Date, "%m/%d/%Y"))
data_2019$year <- format(as.Date(data_2019$Date, format="%m/%d/%Y"),"%Y")
```


```{r Rbind to concatenate data frames and change column names}
df_all <- rbind(data_2004, data_2019)

names(df_all) <- make.names(names(df_all))
names(df_all)[names(df_all) == "Daily.Mean.PM2.5.Concentration"] <- "PM2.5Concentration"

df_all <- df_all[order(df_all$PM2.5Concentration)] #Ascending order by PM 2.5

```






##### 3. Create a basic map in leaflet() that shows the locations of the sites (make sure to use different colors for each year). Summarize the spatial distribution of the monitoring sites.

```{r Plotting leaflet}

pal <- colorFactor(
  palette = c('red', 'blue'),
  domain = df_all$year
)

leaflet(df_all) %>%
  addProviderTiles('OpenStreetMap') %>%
  addCircles(lat=~SITE_LATITUDE,lng=~SITE_LONGITUDE, color = ~pal(year))
```



##### 4. Check for any missing or implausible values of PM 2.5 in the combined dataset. Explore the proportions of each and provide a summary of any temporal patterns you see in these observations.

```{r}
sum(as.numeric(is.na(df_all$PM2.5Concentration)))
```
No missing values

```{r}
summary(df_all$PM2.5Concentration)
```
In the case of concentration of particulate matter in the air, it seems implausible to have a negative concentration. Remove these observations from the data.

```{r View negative readings}
df_all %>%
  filter(PM2.5Concentration < 0) %>%
  group_by(Site.Name, year) %>%
  summarise(negative_readings = n()) %>%
  arrange(desc(negative_readings))
```


```{r View abnormally high concentrations}
df_all %>%
  filter(PM2.5Concentration == max(PM2.5Concentration))
```



##### 5. Explore the main question of interest at three different spatial levels. Create exploratory plots (e.g. boxplots, histograms, line plots) and summary statistics that best suit each level of data. Be sure to write up explanations of what you observe in these data.


```{r Boxplot of concentrations}
boxplot(PM2.5Concentration ~ year, data = df_all, col = df_all$year)
#Probably not the best option, as the data are highly skewed
```


```{r Histograms of concentrations}
par(mfrow = c(2, 1), mar = c(2, 4, 2, 1))
hist(subset(df_all, year == "2004")$PM2.5Concentration, col = "red", breaks = 200, main = "2004 PM 2.5 Concentration", xlab = "PM 2.5")
abline(v = 65, lwd = 2)
abline(v = median(subset(df_all, year == "2004")$PM2.5Concentration), lwd = 2, col = "purple")
hist(subset(df_all, year == "2019")$PM2.5Concentration, col = "blue", breaks = 200, main = "2019 PM 2.5 Concentration", xlab = "PM 2.5")
abline(v = 35, lwd = 2)
abline(v = median(subset(df_all, year == "2019")$PM2.5Concentration), lwd = 2, col = "purple")

#Need to adjust the x-axis to be the same scale
```






```{r, include = FALSE}
wilcox.test(subset(df_all, year == "2004")$PM2.5Concentration, subset(df_all, year == "2019")$PM2.5Concentration)
```
#At .05 significance level, we conclude that the PM2.5 concentrations in 2004 and 2019 from the data set are nonidentical populations.
