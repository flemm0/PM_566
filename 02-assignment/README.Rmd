---
title: "Assignment 02: Data Viz and Wrangling"
author: "Flemming Wu"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

For this assignment, we will be analyzing data from USC’s Children’s Health Study. The learning objectives are to conduct data wrangling and visualize the data with key questions in mind.

### Data Wrangling
You will need to download two datasets from https://github.com/USCbiostats/data-science-data. The individual and regional CHS datasets in 01_chs. The individual data includes personal and health characteristics of children in 12 communities across Southern California. The regional data include air quality measurements at the community level. Once downloaded, you can merge these datasets using the location variable. Once combined, you will need to do the following: \

  1. After merging the data, make sure you don’t have any duplicates by counting the number of rows. Make sure it matches. \

  In the case of missing values, impute data using the average within the variables “male” and “hispanic.” If you are interested (and feel adventurous) in the theme of Data Imputation, take a look at this paper on “Multiple Imputation” using the Amelia R package here. \

  2. Create a new categorical variable named “obesity_level” using the BMI measurement (underweight BMI<14; normal BMI 14-22; overweight BMI 22-24; obese BMI>24). To make sure the variable is rightly coded, create a summary table that contains the minimum BMI, maximum BMI, and the total number of observations per category. \

  3. Create another categorical variable named “smoke_gas_exposure” that summarizes “Second Hand Smoke” and “Gas Stove.” The variable should have four categories in total. \

  4. Create four summary tables showing the average (or proportion, if binary) and sd of “Forced expiratory volume in 1 second (ml)” and asthma indicator by town, sex, obesity level, and “smoke_gas_exposure.” \

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
setwd("~/Desktop/PM566/GitHub/02-assignment")
```

Load libraries
```{r load libraries}
library(data.table)
library(tidyverse)
library(dtplyr)
```

Download data
```{r download data}
if(!file.exists("individual.csv")){
  download.file(url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/01_chs/chs_individual.csv",
               destfile = "individual.csv",
               method = "libcurl",
               timeout = 60)
}

if(!file.exists("regional.csv")){
  download.file(url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/01_chs/chs_regional.csv",
               destfile = "regional.csv",
               method = "libcurl",
               timeout = 60)
}

#Read data tables
individual <- fread("individual.csv")
regional <- fread("regional.csv")

```

Merge data tables and ensure dimensions are correct.
```{r merging data}
#Check rows
dim(individual) #merged data table should contain 1200 rows
dim(regional) #merged data table should have 23 + 26 columns

dat <- merge(x = individual, y = regional, by.x = "townname", by.y = "townname")

#Check dimensions
dim(dat) #1200 rows and 49 columns as expected
```

Impute missing values with averages within variables "male" and "hispanic"
```{r view missing data}
#get columns that have na count greater than 0, and pass them into a vector
cols <- names(which(colSums(is.na(dat)) > 0))


#subset data table for hispanic males and compute averages on the columns of interest
dat[male == 1 & hispanic == 1, lapply(.SD, mean, na.rm = TRUE), .SDcols = cols]
```
```{r}
dat2 <- copy(dat)

dat2[, m_bmi := mean(bmi, na.rm = TRUE), by = .(male, hispanic)]

in_names  <- cols
out_names <- paste0(in_names, "_avg")
(dat3 <- merge(
  
  x = dat[,
  setNames(lapply(.SD, mean, na.rm = TRUE), out_names),
  .SDcols = in_names, 
  by  = .(hispanic, male)
  ],
  
  y = dat2,
  by.x = c("hispanic", "male"),
  by.y = c("hispanic", "male")
))

dat3[,
     c("agepft", "height", "weight", "bmi", "smoke", "asthma", "gasstove", "fev") :=
     .(
       fifelse(is.na(agepft), agepft_avg, agepft),
       fifelse(is.na(height), height_avg, height),
       fifelse(is.na(weight), weight_avg, weight),
       fifelse(is.na(bmi), bmi_avg, bmi),
       fifelse(is.na(smoke), smoke_avg, smoke),
       fifelse(is.na(asthma), asthma_avg, asthma),
       fifelse(is.na(gasstove), gasstove_avg, gasstove),
       fifelse(is.na(fev), fev_avg, fev)
     )
     ]


dat3[, ..cols]
#dat2[rowSums(is.na(dat2)) > 0, ]
```



### Looking at the Data (EDA)
The primary questions of interest are: 1. What is the association between BMI and FEV (forced expiratory volume)? 2. What is the association between smoke and gas exposure and FEV? 3. What is the association between PM2.5 exposure and FEV? \

Follow the EDA checklist from week 3 and the previous assignment. Be sure to focus on the key variables. Visualization Create the following figures and interpret them. Be sure to include easily understandable axes, titles, and legends. \

  1. Facet plot showing scatterplots with regression lines of BMI vs FEV by “townname”.\
  2. Stacked histograms of FEV by BMI category and FEV by smoke/gas exposure. Use different color schemes   3. than the ggplot default. \
  4. Barchart of BMI by smoke/gas exposure. \
  5. Statistical summary graphs of FEV by BMI and FEV by smoke/gas exposure category.\
   6. A leaflet map showing the concentrations of PM2.5 mass in each of the CHS communities.\
  7. Choose a visualization to examine whether PM2.5 mass is associated with FEV.\