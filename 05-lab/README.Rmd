---
title: "05-Lab Data Wrangling"
author: "Flemming Wu"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---
### Learning goals:
##### Use the merge() function to join two datasets.\
##### Deal with missings and impute data.\
##### Identify relevant observations using quantile().\
##### Practice your GitHub skills.\

### Lab description
For this lab we will be, again, dealing with the meteorological dataset downloaded from the NOAA, the met. In this case, we will use data.table to answer some questions regarding the met dataset, while at the same time practice your Git+GitHub skills for this project.

This markdown document should be rendered using github_document document.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the data.table (and the dtplyr and dplyr packages if you plan to work with those).

Load the met data from https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz, and also the station data. For the later, you can use the code we used during lecture to pre-process the stations data:

```{r Load libraries, message = FALSE}
library(data.table)
library(dtplyr)
library(dplyr)
library(lubridate)
```


```{r Download and clean data, message = FALSE, cache = TRUE}
# Load in the met_all data
met <- fread("../04-lab/met_all.gz")
met <- met[met$temp > -17][elev == 9999.0, elev := NA]

# Download the stations data
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

```{r, include = FALSE}
str(stations)
str(met)
```

Merge the data as we did during the lecture.

```{r Merging the data}
dat <- merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  )

```

#### Question 1: Representative station for the US
What is the median station in terms of temperature, wind speed, and atmospheric pressure? Look for the three weather stations that best represent continental US using the quantile() function. Do these three coincide?\
\
Knit the document, commit your changes, and Save it on GitHub. Don’t forget to add README.md to the tree, the first time you render it.

```{r Computes the mean by weather station}
#Summarize the average temperature, wind speed, and atmospheric pressure for each station 
(station_averages <- dat[, .(
  temp = mean(temp, na.rm = TRUE),
  wind.sp = mean(wind.sp, na.rm = TRUE),
  atm.press = mean(atm.press, na.rm = TRUE)
), by = .(USAFID, STATE)])
```
The above computes the mean by weather station. Now let's compute the median value for each variable.

```{r Take median of all the averages of the different stations}
(us_medians <- dat[ , .(
      temp50        = median(temp, na.rm = TRUE),
      windsp50      = median(wind.sp, na.rm = TRUE),
      atmpress50    = median(atm.press, na.rm = TRUE)
)])
```

Now create a new column in the station averages data table that holds the differences between the station averages and the mean across the entire US.

```{r Compute the differences and add new variable to station averages data}
(station_averages <- station_averages[,
                 c("temp50_dist", "wind.sp50_dist", "atmpress50_dist") := 
                     .(abs(temp - us_medians$temp50), 
                       abs(wind.sp - us_medians$windsp50), 
                       abs(atm.press - us_medians$atmpress50))
                 ][order(temp50_dist, wind.sp50_dist, atmpress50_dist)])

```

A helpful function 'which.min()' to find the station that holds the closest average readings to the median of the whole data set for each of the three variables.
```{r }
station_averages[which.min(temp50_dist)] #median station in terms of temperature
station_averages[which.min(wind.sp50_dist)] #median station in terms of wind speed
station_averages[which.min(atmpress50_dist)] #median station in terms of atmospheric pressure
```
The stations closest to national median in temperature, wind speed, and atmospheric pressure seem to be spread around the country, and not consolidated in one state or region.




#### Question 2: Representative station per state
Just like the previous question, you are asked to identify what is the most representative, the median, station per state. This time, instead of looking at one variable at a time, look at the euclidean distance. If multiple stations show in the median, select the one located at the lowest latitude.\

Knit the doc and save it on GitHub.

```{r Calculate medians across states for each of the three variables}
(state_medians <- dat[ , .(
      temp50        = median(temp, na.rm = TRUE),
      windsp50      = median(wind.sp, na.rm = TRUE),
      atmpress50    = median(atm.press, na.rm = TRUE)),
      by = STATE])
```

```{r Merge state medians back with station averages data table}
#Remove distance columns from question 1
station_averages[, c("temp50_dist", "wind.sp50_dist", "atmpress50_dist") := NULL]


#Merge state median values back with station averages to add three new columns
(station_averages <- merge(
  x = station_averages,
  y = state_medians,
  by.x = "STATE",
  by.y = "STATE",
  all.x = TRUE,
  all.y = FALSE
))

```


```{r Calculate observation minus the median for each station in each state}
(station_averages <- station_averages[,
                 c("temp50_dist", "wind.sp50_dist", "atmpress50_dist") := 
                     .(abs(temp - temp50), 
                       abs(wind.sp - windsp50), 
                       abs(atm.press - atmpress50))
                 ])


#(station_averages[, temp50_dist := abs(temp - temp50)])
#station_averages[, wind.sp50_dist := abs(wind.sp - wind.sp50)]
#station_averages[, atm.press50_dist := abs(atm.press - atm.press50)]

```

```{r Compute euclidian distances}
(station_averages[ , eucdist := sqrt(temp50_dist^2 + wind.sp50_dist^2 + atmpress50_dist^2)])
```


```{r Group by state and compute min of each group}
#Group by state, and compute min on eucdist column, which will be the .SD column
#Assign to temporary table
state_eucdist <- station_averages[, lapply(.SD, min, na.rm = T), by = STATE, .SDcols = c("eucdist")]

#search the euclidean distances in the station averages to get the USAFID associated with the stations of interest
station_averages <- station_averages[eucdist %in% state_eucdist[, eucdist]]
```

```{r}
merge(station_averages, dat[ , .(STATE, lat, lon)], by.x = "STATE", by.y = "STATE", all.y = FALSE)
```



#### Question 3: In the middle?
For each state, identify what is the station that is closest to the mid-point of the state. Combining these with the stations you identified in the previous question, use leaflet() to visualize all ~100 points in the same figure, applying different colors for those identified in this question.\

Knit the doc and save it on GitHub.

```{r Finding the GEOGRAPHIC midpoint of each state}
#Find the physical/geographic midpoint of each state using median of the longitudes and latitudes

(state_midpoints <- dat[,
                   .(
                     lat50 = quantile(lat, prob = 0.5, na.rm = TRUE),
                     lon50 = quantile(lon, prob = 0.5, na.rm = TRUE)
                   ),
                   by = "STATE"])

#Merge back to original datatable to obtain station numbers
(state_midpoints <- merge(
  x = state_midpoints,
  y = dat,
  by.x = "STATE",
  by.y = "STATE"
))

#Group new data frame by station
(state_midpoints <- state_midpoints[, .(STATE, lat50, lon50, lat, lon), by = "USAFID"])
#Calculate distance from state midpoint for each station
state_midpoints[, c("lat50_dist", "lon50_dist") := 
                  .(abs(lat - lat50), abs(lon - lon50))]

state_midpoints[, eucdist := sqrt(lat50_dist^2 + lon50_dist^2)]

(state_midpoints <- state_midpoints[, .SD[which.min(eucdist)], by = "STATE"])
```

```{r Merge station_averages and state_midpoints to create plot}

#plot_data <- rbind(state_midpoints[, .(STATE, lat, lon)], station_averages[, .(STATE, lat, lon)])

#Need to create new column for indicating if it is an average or midpoint station


```




#### Question 4: Means of means
Using the quantile() function, generate a summary table that shows the number of states included, average temperature, wind-speed, and atmospheric pressure by the variable “average temperature level,” which you’ll need to create.\
\
Start by computing the states’ average temperature. Use that measurement to classify them according to the following criteria:\
\
low: temp < 20\
Mid: temp >= 20 and temp < 25\
High: temp >= 25\
Once you are done with that, you can compute the following:\
\
```{r}
temp_summary <- dat[, .(avg_temp = mean(temp)), by = STATE]

(temp_summary[, temp_factor := fifelse(avg_temp < 20, "low", 
                             fifelse(avg_temp >= 20 & avg_temp < 25, "mid", "high"))])

```

Number of entries (records),\
Number of NA entries,\
Number of stations,\
Number of states included, and\
Mean temperature, wind-speed, and atmospheric pressure.\
All by the levels described before.\
\
Knit the document, commit your changes, and push them to GitHub. If you’d like, you can take this time to include the link of the issue of the week so that you let us know when you are done, e.g.,


